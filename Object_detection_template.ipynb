{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from src.models.localization.cnn_localizer import CNNLocalizer\n",
    "from src.util.loss_funcs import detection_loss\n",
    "from src.util.transform_dataset import TransformDataset, get_transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.set_default_dtype(torch.float32) # TODO maybe remove\n",
    "batch_size = 128       \n",
    "torch.set_printoptions(profile=\"full\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_in, W_in = 48, 60\n",
    "H_out, W_out = 2, 3\n",
    "CELL_WIDTH, CELL_HEIGHT = W_in / W_out, H_in / H_out\n",
    "\n",
    "def get_cell(x, y):\n",
    "    row = (y * H_in) // (CELL_HEIGHT)\n",
    "    col = (x * W_in) // (CELL_WIDTH)\n",
    "    return int(row), int(col)\n",
    "\n",
    "\n",
    "def convert_Y_label(Y:torch.Tensor):\n",
    "    converted_Y = [[[0,0,0,0,0,0] for _ in range(W_out)] for _ in range(H_out)]\n",
    "\n",
    "    for digit in Y:\n",
    "        p, x, y, w, h, c = digit\n",
    "        row, col = get_cell(x.item(), y.item())\n",
    "\n",
    "        x = ((x * W_in) - col * CELL_WIDTH) / (CELL_WIDTH)\n",
    "        y = ((y * H_in) - row * CELL_HEIGHT) / (CELL_HEIGHT)\n",
    "        w *= W_out\n",
    "        h *= H_out\n",
    "         \n",
    "        converted_Y[row][col] = [p, x, y, w, h, c]\n",
    "\n",
    "    return torch.Tensor(converted_Y)\n",
    "\n",
    "def revert_y_label(Y: torch.Tensor):\n",
    "    reverted_y = []\n",
    "    for row in range(H_out):\n",
    "        for col in range(W_out):\n",
    "            p, x, y, w, h, c = Y[row][col]\n",
    "            x = CELL_WIDTH * x + col * CELL_WIDTH\n",
    "            Y = CELL_HEIGHT * y + row * CELL_HEIGHT\n",
    "            w /= W_out\n",
    "            h /= H_out\n",
    "\n",
    "            reverted_y.append((p, x, y, w, h, c))\n",
    "    return torch.Tensor(reverted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = torch.load(\"data/list_y_true_train.pt\")\n",
    "val_true = torch.load(\"data/list_y_true_val.pt\")\n",
    "test_true = torch.load(\"data/list_y_true_test.pt\")\n",
    "\n",
    "train_images = torch.load(\"data/detection_train.pt\", weights_only=False).tensors[0]\n",
    "print(train_images.shape)\n",
    "val_images = torch.load(\"data/detection_val.pt\", weights_only=False).tensors[0]\n",
    "test_images = torch.load(\"data/detection_test.pt\", weights_only=False).tensors[0]\n",
    "\n",
    "\n",
    "converted_data = [torch.zeros(N, H_out, W_out, 6) for N in [len(train_true), len(val_true), len(test_true)]]\n",
    "for i, dataset in enumerate([train_true, val_true, test_true]):\n",
    "    for j in range(len(dataset)):\n",
    "        converted_data[i][j] = convert_Y_label(dataset[j])\n",
    "\n",
    "train_labels, val_labels, test_labels = converted_data\n",
    "\n",
    "transforms = get_transform(train_images)\n",
    "\n",
    "train_loader = DataLoader(TransformDataset(TensorDataset(train_images, train_labels), transforms), batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(TransformDataset(TensorDataset(val_images, val_labels), transforms), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TransformDataset(TensorDataset(test_images, test_labels), transforms), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.detection.cnn_detector import CNNDetector\n",
    "from itertools import product\n",
    "learning_rates = [0.001]\n",
    "epochs = [20]\n",
    "\n",
    "models = {}\n",
    "\n",
    "for learning_rate, num_epochs in product(learning_rates, epochs):\n",
    "    model = CNNDetector(loss_fn=detection_loss, learning_rate=learning_rate, num_epochs=num_epochs)\n",
    "    model.fit(train_loader)\n",
    "\n",
    "    # IoU_score = compute_IoU_localization(model, val_loader, None)\n",
    "    # accuracy_score = compute_accuracy_localization(model, val_loader, None)\n",
    "\n",
    "    # print(f'Learning rate: {learning_rate}, num_epochs: {num_epochs}')\n",
    "    # print(f'IoU score: {IoU_score}')\n",
    "    # print(f'Accuracy score: {accuracy_score}')\n",
    "    # models[model] = (IoU_score+accuracy_score) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple(img, out, target):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "    img = img.squeeze(0).numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    for row in out.shape[0]: \n",
    "        for col in out.shape[1]: \n",
    "            po, xo, yo, wo, ho, _ = revert_y_label(out[row][col])\n",
    "            pt, xt, yt, wt, ht, _ = revert_y_label(target[row][col])\n",
    "\n",
    "            rectOut = plt.Rectangle(((xo-wo/2) * 60, (yo-ho/2)*48), wo*60, ho*48, linewidth=3, edgecolor='r', facecolor='none')\n",
    "            rectTarget = plt.Rectangle(((xt-wt/2) * 60, (yt-ht/2)*48), wt*60, ht*48, linewidth=3, edgecolor='g', facecolor='none')\n",
    "\n",
    "            if po > 0:\n",
    "                ax.add_patch(rectOut)\n",
    "            if pt:\n",
    "                ax.add_patch(rectTarget)\n",
    "            # ax.text(0, 53, f\"{out},\\n{target[row][col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(models, key=models.get)\n",
    "images, labels = next(iter(val_loader))\n",
    "outs = model.predict(images).cpu()\n",
    "for i in range(20):\n",
    "    draw_multiple(images[i], outs[i], labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
