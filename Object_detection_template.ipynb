{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from src.util.loss_funcs import detection_loss\n",
    "from src.util.transform_dataset import TransformDataset, get_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.set_default_dtype(torch.float32)  # TODO maybe remove\n",
    "batch_size = 128\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_in, W_in = 48, 60\n",
    "H_out, W_out = 2, 3\n",
    "CELL_WIDTH, CELL_HEIGHT = W_in / W_out, H_in / H_out\n",
    "\n",
    "\n",
    "def get_cell(x, y):\n",
    "    row = (y * H_in) // (CELL_HEIGHT)\n",
    "    col = (x * W_in) // (CELL_WIDTH)\n",
    "    return int(row), int(col)\n",
    "\n",
    "\n",
    "def convert_Y_label(Y):\n",
    "    converted_Y = [[[0, 0, 0, 0, 0, 0] for _ in range(W_out)] for _ in range(H_out)]\n",
    "\n",
    "    for digit in Y:\n",
    "        p, x, y, w, h, c = digit\n",
    "        row, col = get_cell(x.item(), y.item())\n",
    "        x = ((x * W_in) - col * CELL_WIDTH) / (CELL_WIDTH)\n",
    "        y = ((y * H_in) - row * CELL_HEIGHT) / (CELL_HEIGHT)\n",
    "        w *= W_out\n",
    "        h *= H_out\n",
    "\n",
    "        converted_Y[row][col] = [p, x, y, w, h, c]\n",
    "\n",
    "    return torch.Tensor(converted_Y)\n",
    "\n",
    "\n",
    "def revert_y_label(Y):\n",
    "    reverted_y = []\n",
    "    for row in range(H_out):\n",
    "        reverted_y.append([])\n",
    "        for col in range(W_out):\n",
    "            p, x, y, w, h, c = Y[row][col]\n",
    "            x = (x * CELL_WIDTH + col * CELL_WIDTH) / W_in\n",
    "            y = (y * CELL_HEIGHT + row * CELL_HEIGHT) / H_in\n",
    "            w /= W_out\n",
    "            h /= H_out\n",
    "\n",
    "            reverted_y[row].append((p, x, y, w, h, c))\n",
    "    return torch.Tensor(reverted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = torch.load(\"data/list_y_true_train.pt\")\n",
    "val_true = torch.load(\"data/list_y_true_val.pt\")\n",
    "test_true = torch.load(\"data/list_y_true_test.pt\")\n",
    "\n",
    "train_images = torch.load(\"data/detection_train.pt\", weights_only=False).tensors[0]\n",
    "val_images = torch.load(\"data/detection_val.pt\", weights_only=False).tensors[0]\n",
    "test_images = torch.load(\"data/detection_test.pt\", weights_only=False).tensors[0]\n",
    "\n",
    "\n",
    "converted_data = [\n",
    "    torch.zeros(N, H_out, W_out, 6)\n",
    "    for N in [len(train_true), len(val_true), len(test_true)]\n",
    "]\n",
    "for i, dataset in enumerate([train_true, val_true, test_true]):\n",
    "    for j in range(len(dataset)):\n",
    "        converted_data[i][j] = convert_Y_label(dataset[j])\n",
    "\n",
    "train_labels, val_labels, test_labels = converted_data\n",
    "\n",
    "transforms = get_transform(train_images)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TransformDataset(TensorDataset(train_images, train_labels), transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TransformDataset(TensorDataset(val_images, val_labels), transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TransformDataset(TensorDataset(test_images, test_labels), transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics.detection\n",
    "\n",
    "\n",
    "def prune_data(pred, target):\n",
    "    reverted_pred, reverted_target = revert_y_label(pred).view(-1, 6), revert_y_label(\n",
    "        target\n",
    "    ).view(-1, 6)\n",
    "    pruned_pred, pruned_target = [], []\n",
    "\n",
    "    for i in range(pred.shape[0]):\n",
    "        if reverted_pred[i][0] > 0.5:\n",
    "            pruned_pred.append(reverted_pred[i])\n",
    "        if reverted_target[i][0]:\n",
    "            pruned_target.append(reverted_target[i])\n",
    "\n",
    "    pruned_preds_tensor = None if not pruned_pred else torch.stack(pruned_pred, dim=0)\n",
    "    pruned_target_tensor = (\n",
    "        None if not pruned_target else torch.stack(pruned_target, dim=0)\n",
    "    )\n",
    "\n",
    "    return pruned_preds_tensor, pruned_target_tensor\n",
    "\n",
    "\n",
    "def compute_mAP(model, loader):\n",
    "    mAP_metric = torchmetrics.detection.MeanAveragePrecision(\n",
    "        box_format=\"cxcywh\",\n",
    "        iou_type=\"bbox\",\n",
    "        iou_thresholds=[0.5],\n",
    "        backend=\"pycocotools\",\n",
    "    )\n",
    "    pred_dicts, target_dicts = [], []\n",
    "\n",
    "    for X, targets in loader:\n",
    "        preds = model.predict(X)\n",
    "        for pred, target in zip(preds, targets):\n",
    "            pruned_preds, pruned_target = prune_data(pred, target)\n",
    "\n",
    "            pred_dicts.append(\n",
    "                {\n",
    "                    \"boxes\": (\n",
    "                        pruned_preds[:, 1:5]\n",
    "                        if pruned_preds is not None\n",
    "                        else torch.empty(0, 4)\n",
    "                    ),\n",
    "                    \"scores\": (\n",
    "                        pruned_preds[:, 0]\n",
    "                        if pruned_preds is not None\n",
    "                        else torch.empty(0)\n",
    "                    ),\n",
    "                    \"labels\": (\n",
    "                        pruned_preds[:, 5].long()\n",
    "                        if pruned_preds is not None\n",
    "                        else torch.empty(0, dtype=torch.long)\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            target_dicts.append(\n",
    "                {\n",
    "                    \"boxes\": (\n",
    "                        pruned_target[:, 1:5]\n",
    "                        if pruned_target is not None\n",
    "                        else torch.empty(0, 4)\n",
    "                    ),\n",
    "                    \"labels\": (\n",
    "                        pruned_target[:, 5].long()\n",
    "                        if pruned_target is not None\n",
    "                        else torch.empty(0, dtype=torch.long)\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        mAP_metric.update(preds=pred_dicts, target=target_dicts)\n",
    "\n",
    "    return mAP_metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.detection.cnn_detector import CNNDetector\n",
    "from itertools import product\n",
    "\n",
    "learning_rates = [1e-2, 1e-3, 1e-4]\n",
    "weight_decays = [1e-2, 1e-3]\n",
    "momentums = [0.8, 0.9]\n",
    "max_epochs = 300\n",
    "models = {}\n",
    "\n",
    "for learning_rate, weight_decay, momentum in product(\n",
    "    learning_rates, weight_decays, momentums\n",
    "):\n",
    "    model = CNNDetector(\n",
    "        loss_fn=detection_loss,\n",
    "        learning_rate=learning_rate,\n",
    "        max_epochs=max_epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        momentum=momentum,\n",
    "    )\n",
    "    model.fit(train_loader, val_loader, delta=0.03, patience=3)\n",
    "\n",
    "    mAP_score = compute_mAP(model, val_loader)\n",
    "    print(\n",
    "        f\"Model with lr: {learning_rate} — weight wecay: {weight_decay} — momentum: {momentum}\\nmAP score: {mAP_score}\"\n",
    "    )\n",
    "    models[model] = mAP_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple(img, out, target):\n",
    "    out = revert_y_label(out)\n",
    "    target = revert_y_label(target)\n",
    "    _, ax = plt.subplots()\n",
    "    img = img.squeeze(0).numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    ax.set_xticks(np.arange(0, img.shape[1], CELL_WIDTH))\n",
    "    ax.set_yticks(np.arange(0, img.shape[0], CELL_HEIGHT))\n",
    "    ax.grid(True, color=\"b\", linestyle=\"-\", linewidth=2)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    for row in range(out.shape[0]):\n",
    "        for col in range(out.shape[1]):\n",
    "            po, xo, yo, wo, ho, _ = out[row][col]\n",
    "            pt, xt, yt, wt, ht, _ = target[row][col]\n",
    "            rectOut = plt.Rectangle(\n",
    "                ((xo - wo / 2) * 60, (yo - ho / 2) * 48),\n",
    "                wo * 60,\n",
    "                ho * 48,\n",
    "                linewidth=3,\n",
    "                edgecolor=\"r\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            rectTarget = plt.Rectangle(\n",
    "                ((xt - wt / 2) * 60, (yt - ht / 2) * 48),\n",
    "                wt * 60,\n",
    "                ht * 48,\n",
    "                linewidth=3,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            if po > 0.5:\n",
    "                ax.add_patch(rectOut)\n",
    "            ax.add_patch(rectTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(models, key=models.get)\n",
    "images, labels = next(iter(val_loader))\n",
    "outs = best_model.predict(images).cpu()\n",
    "for i in range(20):\n",
    "    draw_multiple(images[i], outs[i], labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
