{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.localization.cnn_localizer import CNNLocalizer\n",
    "from src.util.loss_funcs import localization_loss\n",
    "from src.util.transform_dataset import TransformDataset, get_transform\n",
    "from torch.nn import Sigmoid\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.set_default_dtype(torch.float32) # TODO maybe remove\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(bb1, bb2):\n",
    "    left = max(bb1[0] - bb1[2]/2, bb2[0] - bb2[2]/2)\n",
    "    right = min(bb1[0] + bb1[2]/2, bb2[0] + bb2[2]/2)\n",
    "    top = max(bb1[1] - bb1[3]/2, bb2[1] - bb2[3]/2)\n",
    "    bot = min(bb1[1] + bb1[3]/2, bb2[1] + bb2[3]/2)\n",
    "\n",
    "    if left >= right or bot >= top:\n",
    "        return 0\n",
    "    \n",
    "    width = right - left\n",
    "    height = top - bot\n",
    "\n",
    "    return width*height\n",
    "   \n",
    "def IoU(bb1, bb2):\n",
    "    intersect_area = intersection(bb1, bb2)\n",
    "    return intersect_area / (bb1[2]*bb1[3] + bb2[2] * bb2[3] - intersect_area)\n",
    "   \n",
    "def compute_IoU_localization(model, loader, preprocessor):\n",
    "    \"\"\"\n",
    "    Compute IoU performance of the model on the given dataset\n",
    "    \"\"\"\n",
    "    IoU_scores = []\n",
    "    for images, labels in loader:\n",
    "        out = model.predict(images)\n",
    "        for pred, target in zip(out, labels):\n",
    "            bb1 = pred[1:5]\n",
    "            bb2 = target[1:5]\n",
    "            predicted_detection = F.sigmoid(pred[0]).item() > 0.5\n",
    "            IoU_scores.append(IoU(bb1, bb2) if target[0] else predicted_detection == False)\n",
    "    \n",
    "    return torch.mean(torch.Tensor(IoU_scores))\n",
    "\n",
    "\n",
    "def compute_accuracy_localization(model, loader, preprocessor):\n",
    "    \"\"\"\n",
    "    Compute accuracy of the model on the given dataset\n",
    "    \"\"\"\n",
    "    accuracy_scores = []\n",
    "    for images, labels in loader:\n",
    "        out = model.predict(images)\n",
    "        for pred, target in zip(out,labels):\n",
    "            pred_class = torch.argmax(pred[5:])\n",
    "            predicted_detection = F.sigmoid(pred[0]).item() > 0.5\n",
    "            accuracy_scores.append(pred_class == target[5] and predicted_detection == target[0] or not target[0] and not predicted_detection)\n",
    "            \n",
    "    return torch.mean(torch.Tensor(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = torch.load(\"data/localization_train.pt\", weights_only=False)\n",
    "train_transform = get_transform(train.tensors[0])\n",
    "train = TransformDataset(train, train_transform)\n",
    "\n",
    "val = torch.load(\"data/localization_val.pt\", weights_only=False)\n",
    "val = TransformDataset(val, train_transform)\n",
    "\n",
    "test = torch.load(\"data/localization_test.pt\", weights_only=False)\n",
    "test = TransformDataset(test, train_transform)\n",
    "\n",
    "# TODO seed data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "learning_rates = [1e-2, 1e-1]\n",
    "epochs = [0, 5, 10]\n",
    "\n",
    "models = {}\n",
    "\n",
    "for learning_rate, num_epochs in product(learning_rates, epochs):\n",
    "    model = CNNLocalizer(loss_fn=localization_loss, learning_rate=learning_rate, num_epochs=num_epochs)\n",
    "    model.fit(train_loader)\n",
    "\n",
    "    IoU_score = compute_IoU_localization(model, val_loader, None)\n",
    "    accuracy_score = compute_accuracy_localization(model, val_loader, None)\n",
    "\n",
    "    print(f'Learning rate: {learning_rate}, num_epochs: {num_epochs}')\n",
    "    print(f'IoU score: {IoU_score}')\n",
    "    print(f'Accuracy score: {accuracy_score}')\n",
    "    models[model] = (IoU_score+accuracy_score) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, out, target):\n",
    "    po, xo, yo, wo, ho = out[0:5]\n",
    "    pt, xt, yt, wt, ht = target[0:5]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    img = img.squeeze(0).numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    rectOut = plt.Rectangle(((xo-wo/2) * 60, (yo-ho/2)*48), wo*60, ho*48, linewidth=3, edgecolor='r', facecolor='none')\n",
    "    rectTarget = plt.Rectangle(((xt-wt/2) * 60, (yt-ht/2)*48), wt*60, ht*48, linewidth=3, edgecolor='g', facecolor='none')\n",
    "\n",
    "    ax.add_patch(rectOut)\n",
    "    ax.add_patch(rectTarget)\n",
    "    ax.text(0, 53, f\"{out},\\n{target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(models, key=models.get)\n",
    "images, labels = next(iter(val_loader))\n",
    "outs = model.predict(images).cpu()\n",
    "for i in range(20):\n",
    "    draw(images[i], outs[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
