{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil, floor\n",
    "from datetime import datetime \n",
    "from dataclasses import dataclass\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset as torchDataset\n",
    "from src.models.localization.cnn_localizer import CNNLocalizer\n",
    "from src.util.loss_funcs import localization_loss\n",
    "import seaborn as sns\n",
    "from src.util.transform_dataset import TransformDataset, get_transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.set_default_dtype(torch.float32) # TODO maybe remove\n",
    "batch_sizes = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done in seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(bb1, bb2):\n",
    "    left = max(bb1[0] - bb1[2]/2, bb2[0] - bb2[2]/2)\n",
    "    right = min(bb1[0] + bb1[2]/2, bb2[0] + bb2[2]/2)\n",
    "    top = max(bb1[1] - bb1[3]/2, bb2[1] - bb2[3]/2)\n",
    "    bot = min(bb1[1] + bb1[3]/2, bb2[1] + bb2[3]/2)\n",
    "\n",
    "    if left >= right or bot >= top:\n",
    "        return 0\n",
    "    \n",
    "    width = right - left\n",
    "    height = top - bot\n",
    "\n",
    "    return width*height\n",
    "   \n",
    "def IoU(bb1, bb2):\n",
    "    intersect_area = intersection(bb1, bb2)\n",
    "    return intersect_area / (bb1[2]*bb1[3] + bb2[2] * bb2[3] - intersect_area)\n",
    "   \n",
    "def compute_IoU_localization(model, loader, preprocessor):\n",
    "    \"\"\"\n",
    "    Compute IoU performance of the model on the given dataset\n",
    "    \"\"\"\n",
    "    IoU_scores = []\n",
    "    for images, labels in loader:\n",
    "        out = model.predict(images)\n",
    "        for pred, target in zip(out, labels):\n",
    "            bb1 = pred[1:5]\n",
    "            bb2 = target[1:5]\n",
    "            IoU_scores.append(IoU(bb1, bb2))\n",
    "    \n",
    "    return torch.mean(torch.Tensor(IoU_scores))\n",
    "\n",
    "\n",
    "def compute_accuracy_localization(model, loader, preprocessor):\n",
    "    \"\"\"\n",
    "    Compute accuracy of the model on the given dataset\n",
    "    \"\"\"\n",
    "    accuracy_scores = 0\n",
    "    n = 0\n",
    "    for images, labels in loader:\n",
    "        out = model.predict(images)\n",
    "        for pred, target in zip(out,labels):\n",
    "            pred_class = torch.argmax(pred[5:])\n",
    "            pc = pred[0] > 0 \n",
    "            accuracy_scores += pred_class == target[5] and pc == target[0]\n",
    "            n+=1\n",
    "            \n",
    "    \n",
    "    return accuracy_scores / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = torch.load(\"data/localization_train.pt\")\n",
    "train_transform = get_transform(train.tensors[0])\n",
    "train = TransformDataset(train, train_transform)\n",
    "\n",
    "val = torch.load(\"data/localization_val.pt\")\n",
    "val = TransformDataset(val, train_transform)\n",
    "\n",
    "test = torch.load(\"data/localization_test.pt\")\n",
    "test = TransformDataset(test, train_transform)\n",
    "\n",
    "# TODO seed data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_sizes, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_sizes, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_sizes, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.trial.FrozenTrial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 5, 20)\n",
    "\n",
    "    model = CNNLocalizer(loss_fn=localization_loss, learning_rate=learning_rate, num_epochs=num_epochs)\n",
    "    model.fit(train_loader)\n",
    "\n",
    "    IoU_score = compute_IoU_localization(model, val_loader, None)\n",
    "    accuracy_score = compute_accuracy_localization(model, val_loader, None)\n",
    "\n",
    "    return (IoU_score + accuracy_score) / 2\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f'Best validation score: {study.best_value}')\n",
    "print(f'Best params: {study.best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, out, target):\n",
    "    po, xo, yo, wo, ho = out[0:5]\n",
    "    pt, xt, yt, wt, ht = target[0:5]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    img = img.squeeze(0).numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    rectOut = plt.Rectangle(((xo-wo/2) * 60, (yo-ho/2)*48), wo*60, ho*48, linewidth=3, edgecolor='r', facecolor='none')\n",
    "    rectTarget = plt.Rectangle(((xt-wt/2) * 60, (yt-ht/2)*48), wt*60, ht*48, linewidth=3, edgecolor='g', facecolor='none')\n",
    "\n",
    "    ax.add_patch(rectOut)\n",
    "    ax.add_patch(rectTarget)\n",
    "    ax.text(0, 53, f\"{out},\\n{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLocalizer(loss_fn=localization_loss, learning_rate=study.best_params[\"learning_rate\"], num_epochs=study.best_params[\"num_epochs\"])\n",
    "model.fit(train_loader)\n",
    "images, labels = next(iter(val_loader))\n",
    "outs = model.predict(images)\n",
    "for i in range(10):\n",
    "    draw(images[i], outs[i].cpu(), labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
